{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CorALS - Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare parallelization\n",
    "\n",
    "Before running anything, we make sure that `numpy` will not  oversubscribe CPUs and slow things down.\n",
    "Note that this has to be executed **before importing `numpy`**.\n",
    "\n",
    "* For full correlation matrix calculation, setting `n_threads > 1` can be used to parallelize the calculation.\n",
    "* For the top-k approaches, setting `n_threads=1` makes the most sense, since parallelization is specified separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/corals/threads.py:48: UserWarning: This function should be called before `numpy` or similar modules are imported.\n",
      "  warnings.warn(\"This function should be called before `numpy` or similar modules are imported.\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from corals.threads import set_threads_for_external_libraries\n",
    "set_threads_for_external_libraries(n_threads=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample-gene matrix data\n",
    "sample_gene_matrix = pd.read_csv('crc_pancan_mrna.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_name = \"Primary (Early Age Diagnosis)\"\n",
    "# Load the sample groups\n",
    "sample_groups = pd.read_csv(f'crc_eas_signatures/spl-full_CRCEAS_{sig_name}.csv', index_col=0)\n",
    "sample_groups = sample_groups.rename(columns={'cluster': 'group'})\n",
    "\n",
    "# Load the gene groups\n",
    "gene_groups = pd.read_csv(f'crc_eas_signatures/sig_CRCEAS_{sig_name}.csv', index_col=0)\n",
    "gene_groups = gene_groups.rename(columns={'cluster': 'group'})\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each group of samples and genes\n",
    "for group in sample_groups['group'].unique():\n",
    "    group_samples = sample_groups[sample_groups['group'] == group].index\n",
    "    group_genes = gene_groups[gene_groups['group'] == group].index\n",
    "    # Get the intersection of available samples and genes\n",
    "    available_samples = group_samples.intersection(sample_gene_matrix.columns)\n",
    "    available_genes = group_genes.intersection(sample_gene_matrix.index)\n",
    "    # Extract the corresponding subset of the sample-gene matrix data\n",
    "    group_data = sample_gene_matrix.loc[available_genes, available_samples].transpose()\n",
    "    group_data = group_data.fillna(0)\n",
    "\n",
    "    # df to array\n",
    "    X = group_data.to_numpy()\n",
    "    # reusing correlation from the top-k example\n",
    "    # runtime: ~5 sec with `n_jobs=8`\n",
    "\n",
    "\n",
    "    # FULL\n",
    "    from corals.correlation.full.default import cor_full\n",
    "    cor_values = cor_full(X)\n",
    "    cor_full = pd.DataFrame(cor_values, columns = group_data.columns)\n",
    "    cor_full.index = group_data.columns\n",
    "    # Save the extracted data to a new CSV file\n",
    "    filename = f\"corfull_{sig_name}_{group}.csv\"\n",
    "    cor_full.to_csv(filename)\n",
    "\n",
    "    # TOP K\n",
    "\n",
    "    n_samples = X.shape[0]\n",
    "    n_features = X.shape[1]\n",
    "    print(n_samples)\n",
    "    print(n_features)\n",
    "\n",
    "    from corals.correlation.topk.default import cor_topk\n",
    "    cor_topk_values, cor_topk_coo = cor_topk(X, correlation_type=\"spearman\", k=0.01, n_jobs=8)\n",
    "\n",
    "    from corals.correlation.utils import derive_pvalues, multiple_test_correction\n",
    "    # calculate p-values\n",
    "    pvalues = derive_pvalues(cor_topk_values, n_samples)\n",
    "\n",
    "\n",
    "\n",
    "    cor = pd.DataFrame(cor_topk_values, columns=['cor'])\n",
    "    p = pd.DataFrame(pvalues, columns=['pvalue'])\n",
    "    coo = pd.DataFrame(cor_topk_coo).transpose()\n",
    "    pair = pd.DataFrame({\n",
    "        'start': group_data.columns[cor_topk_coo[0]],\n",
    "        'end': group_data.columns[cor_topk_coo[1]]\n",
    "    })\n",
    "    # concatenate the two dataframes horizontally\n",
    "    df_concat = pd.concat([coo, pair, cor, p], axis=1)\n",
    "    # Save the extracted data to a new CSV file\n",
    "\n",
    "\n",
    "    # Save the extracted data to a new CSV file\n",
    "    filename = f\"topk_{sig_name}_{group}.csv\"\n",
    "    df_concat.to_csv(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/corals/correlation/full/matmul.py:53: RuntimeWarning: invalid value encountered in divide\n",
      "  XX /= std * X.shape[0]\n",
      "/opt/homebrew/lib/python3.10/site-packages/corals/correlation/full/matmul.py:59: RuntimeWarning: invalid value encountered in divide\n",
      "  YY = X / std\n",
      "/opt/homebrew/lib/python3.10/site-packages/corals/correlation/utils.py:8: RuntimeWarning: invalid value encountered in divide\n",
      "  Xh /= np.std(Xh, axis=0) * np.sqrt(X.shape[0])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/qixu/Github/corals-lib-python/docs/notebooks/quickstart.ipynb Cell 7\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/qixu/Github/corals-lib-python/docs/notebooks/quickstart.ipynb#X12sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(n_features)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/qixu/Github/corals-lib-python/docs/notebooks/quickstart.ipynb#X12sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcorals\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorrelation\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtopk\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdefault\u001b[39;00m \u001b[39mimport\u001b[39;00m cor_topk\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/qixu/Github/corals-lib-python/docs/notebooks/quickstart.ipynb#X12sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m cor_topk_values, cor_topk_coo \u001b[39m=\u001b[39m cor_topk(X, correlation_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mspearman\u001b[39;49m\u001b[39m\"\u001b[39;49m, k\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/qixu/Github/corals-lib-python/docs/notebooks/quickstart.ipynb#X12sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcorals\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorrelation\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m derive_pvalues, multiple_test_correction\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/qixu/Github/corals-lib-python/docs/notebooks/quickstart.ipynb#X12sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# calculate p-values\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/corals/correlation/topk/_deprecated/original.py:233\u001b[0m, in \u001b[0;36mtopk_balltree_combined_tree_parallel_optimized\u001b[0;34m(X, Y, correlation_type, k, threshold, approximation_factor, tree_kwargs, dualtree, breadth_first, query_sort, n_batches, n_jobs, n_jobs_transfer_mode, symmetrize, argtopk_method, require_sorted_topk)\u001b[0m\n\u001b[1;32m    230\u001b[0m     tree_kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m    232\u001b[0m \u001b[39m# build tree; note that we concatenate Xh and -Xh to capture negative correlations\u001b[39;00m\n\u001b[0;32m--> 233\u001b[0m tree \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39;49mneighbors\u001b[39m.\u001b[39;49mBallTree(np\u001b[39m.\u001b[39;49mconcatenate([Xh, \u001b[39m-\u001b[39;49mXh], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mtranspose(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtree_kwargs)\n\u001b[1;32m    235\u001b[0m \u001b[39m# define bins\u001b[39;00m\n\u001b[1;32m    236\u001b[0m bins \u001b[39m=\u001b[39m derive_bins(Yh\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], n_batches)\n",
      "File \u001b[0;32msklearn/neighbors/_binary_tree.pxi:833\u001b[0m, in \u001b[0;36msklearn.neighbors._ball_tree.BinaryTree.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[1;32m    922\u001b[0m             array,\n\u001b[1;32m    923\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    924\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    925\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    926\u001b[0m         )\n\u001b[1;32m    928\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "group = \"G1\"\n",
    "group_samples = sample_groups[sample_groups['group'] == group].index\n",
    "group_genes = gene_groups[gene_groups['group'] == group].index\n",
    "# Get the intersection of available samples and genes\n",
    "available_samples = group_samples.intersection(sample_gene_matrix.columns)\n",
    "available_genes = group_genes.intersection(sample_gene_matrix.index)\n",
    "# Extract the corresponding subset of the sample-gene matrix data\n",
    "group_data = sample_gene_matrix.loc[available_genes, available_samples].transpose()\n",
    "group_data = group_data.fillna(0)\n",
    "\n",
    "\n",
    "# df to array\n",
    "X = group_data.to_numpy()\n",
    "# reusing correlation from the top-k example\n",
    "# runtime: ~5 sec with `n_jobs=8`\n",
    "\n",
    "\n",
    "# FULL\n",
    "from corals.correlation.full.default import cor_full\n",
    "cor_values = cor_full(X)\n",
    "cor_full = pd.DataFrame(cor_values, columns = group_data.columns)\n",
    "cor_full.index = group_data.columns\n",
    "# Save the extracted data to a new CSV file\n",
    "filename = f\"corfull_{sig_name}_{group}.csv\"\n",
    "cor_full.to_csv(filename)\n",
    "\n",
    "# TOP K\n",
    "n_samples = X.shape[0]\n",
    "n_features = X.shape[1]\n",
    "print(n_samples)\n",
    "print(n_features)\n",
    "\n",
    "from corals.correlation.topk.default import cor_topk\n",
    "cor_topk_values, cor_topk_coo = cor_topk(X, correlation_type=\"spearman\", k=0.1, n_jobs=8)\n",
    "\n",
    "from corals.correlation.utils import derive_pvalues, multiple_test_correction\n",
    "# calculate p-values\n",
    "pvalues = derive_pvalues(cor_topk_values, n_samples)\n",
    "\n",
    "\n",
    "\n",
    "cor = pd.DataFrame(cor_topk_values, columns=['cor'])\n",
    "p = pd.DataFrame(pvalues, columns=['pvalue'])\n",
    "coo = pd.DataFrame(cor_topk_coo).transpose()\n",
    "pair = pd.DataFrame({\n",
    "    'start': group_data.columns[cor_topk_coo[0]],\n",
    "    'end': group_data.columns[cor_topk_coo[1]]\n",
    "})\n",
    "# concatenate the two dataframes horizontally\n",
    "df_concat = pd.concat([coo, pair, cor, p], axis=1)\n",
    "# Save the extracted data to a new CSV file\n",
    "\n",
    "\n",
    "# Save the extracted data to a new CSV file\n",
    "filename = f\"topk_{sig_name}_{group}.csv\"\n",
    "df_concat.to_csv(filename)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
